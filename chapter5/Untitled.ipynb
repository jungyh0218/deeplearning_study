{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import Chapter5_backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relu activate function\n",
    "# y=x (x>0), y=0 (x <= 0)\n",
    "# dy/dx = 1 (x>0), dy/dx = 0 (x <= 0)\n",
    "\n",
    "class Relu(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True]\n",
      " [ True False]]\n",
      "[[False  True]\n",
      " [ True False]]\n",
      "out:  [[1. 0.]\n",
      " [0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "relu_layer = Relu()\n",
    "out = relu_layer.forward(x)\n",
    "print(relu_layer.mask)\n",
    "print('out: ', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(relu_layer.backward(np.array([[1, 1], [1, 1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid activate function\n",
    "# y = 1/(1+exp(-x))\n",
    "class Sigmoid(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out #sigmoid 의 미분 값은 출력값만으로 계산할 수 있음.\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affine and Softmax\n",
    "#Affine은 WX + b 를 수행하는 연산을 의미함.\n",
    "\n",
    "class Affine(BaseLayer):\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis = 0)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#출력 정규화를 위한 softmax with loss 함수 구현\n",
    "class Softmax(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.args = None\n",
    "        self.S = None\n",
    "        self.dS = None\n",
    "        self.dargs = None\n",
    "        self.out = None\n",
    "        self.dout = None\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        self.args = x\n",
    "        exp_val = np.exp(self.args)\n",
    "        self.S = np.sum(exp_val)\n",
    "        self.out = exp_val/self.S\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # -t/y 가 흘러들어옴\n",
    "        self.dout = self.out * (1+dout)\n",
    "        return self.dout\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "print(Softmax().forward(np.array([0.3, 2.9, 4.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyErrorLayer(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        self.dot_val = None\n",
    "        self.sum_val = None\n",
    "        self.mul_minusone = None\n",
    "        \n",
    "    def forward(self, y, t):\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        delta = 1e-7\n",
    "        self.dot_val = np.dot(np.log(self.y + delta), t)\n",
    "        self.sum_val = np.sum(self.dot_val)\n",
    "        self.mul_minusone = self.sum_val * (-1)\n",
    "        return self.mul_minusone\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        self.dout = -1 * self.t / (self.y+1e-7)\n",
    "        return self.dout\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0 -1  0  0  0  0  0  0  0]\n",
      "[ 0.          0.         -1.66666639  0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "cee = CrossEntropyErrorLayer()\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "res = cee.forward(np.array(y), np.array(t))\n",
    "print(cee.backward(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30571432905300044\n"
     ]
    }
   ],
   "source": [
    "arr = [0.3, 2.9, 4.0]\n",
    "sm = Softmax()\n",
    "cee = CrossEntropyErrorLayer()\n",
    "L = cee.forward(sm.forward(np.array(arr)), np.array([0, 0, 1]))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0 -1]\n",
      "[ 0.01821127  0.24519181 -0.26340295]\n"
     ]
    }
   ],
   "source": [
    "dL = sm.backward(cee.backward(1))\n",
    "print(dL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
